# ğŸ“˜ Fundamentals of Software Engineering for Data

Welcome to the **Fundamentals of Software Engineering for Data** course repository! This course is designed for beginners who are pursuing a career in **data science, data analytics**, or **machine learning**, and provides the essential software engineering skills to build strong technical foundations.

---

## ğŸ“š Course Overview

This hands-on course introduces key tools and concepts widely used in the data ecosystem, including:

- ğŸ§ GNU/Linux and Shell Scripting  
- ğŸ Python Programming (standard & third-party libraries)  
- ğŸ—ƒï¸ Databases and SQL (SQLite, SQLAlchemy)  
- ğŸŒ Web APIs using FastAPI  
- ğŸ§ª Git & GitHub for version control  
- ğŸ§± dbt for analytics engineering  
- ğŸ³ Docker and Docker Compose for containerization  

Each lesson includes **theory, lab exercises**, and **mini-projects** to reinforce practical understanding.

---

## ğŸ§  Prerequisites

**None.** This course is beginner-friendly and welcomes all learners interested in building software skills for data-related roles.

---

## ğŸ§‘â€ğŸ« Instructor

**Tien Nguyen** â€“ Machine Learning Engineer at [MoMo](https://momo.vn) with over 3 years of experience in data and machine learning.

---

## ğŸ–¥ï¸ System Requirements

- Minimum **16GB RAM**
- At least **150GB free disk space**
- OS: Windows, macOS, or Linux

---

## ğŸ“† Schedule & Learning Mode

- ğŸ“ **Live sessions via Zoom**: Every **Tuesday & Thursday**
- ğŸ¥ **Recordings** will be shared after each session

---

## ğŸ§ª Curriculum Breakdown

| Module              | Topics Covered                                                                                                                                       | Lab Activities                                                                                          |
|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| **Linux**           | GNU/Linux basics, bash scripting, Makefile, CronJob                                                                                                   | Build a CLI tool to crawl & collect text from websites                                                  |
| **Python I**        | Syntax, data types, loops, functions, file handling                                                                                                   | Analyze word frequency in crawled documents                                                             |
| **Python II**       | Standard libraries, pip, argparse, error handling, regex                                                                                              | Enhance word counter using Regex and NLTK                                                               |
| **Database & SQL**  | SQL basics, SQLite, SQLAlchemy                                                                                                                        | Save TF-IDF results to a database                                                                       |
| **WebAPI I**        | FastAPI, HTTP methods, Swagger, Postman, Locust                                                                                                       | Build an API for classifying documents                                                                  |
| **WebAPI II**       | Pydantic, error handling, health checks, logging                                                                                                      | Improve the API with response models and monitoring                                                     |
| **Git & GitHub**    | Git basics, GitHub workflow, resolving conflicts, collaboration best practices                                                                        | Track and version your API using Git and GitHub                                                         |
| **dbt**             | Setup, models, materializations, pipelines, testing, documentation                                                                                   | Rebuild workflow using dbt and SQL                                                                      |
| **Docker**          | Dockerfile, building/running containers, PostgreSQL in Docker                                                                                         | Containerize API and connect to PostgreSQL                                                              |
| **Docker Compose**  | Compose file, multi-container setup, environment config, volume persistence                                                                           | Define and run API + PostgreSQL stack using Docker Compose                                              |

---

## ğŸš€ Outcomes

By the end of this course, you will:

âœ… Understand key software tools used in data workflows  
âœ… Be able to build, version, and deploy real-world data applications  
âœ… Have hands-on experience with APIs, databases, containers, and pipelines  
âœ… Be ready to take on more advanced topics in data science and machine learning

---

## ğŸ§­ Getting Started

1
